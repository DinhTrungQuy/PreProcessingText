{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khai báo chuỗi cần xử lý\n",
    "text = \"\"\"Việc Man City kiểm soát bóng vượt trội và hệ thống lùi quanh vòng cấm của Man Utd chính là sự lựa chọn chiến thuật của Erik ten Hag. Sau trận, chính HLV người Hà Lan khẳng định \"Quỷ đỏ\" thực hiện đúng kế hoạch và đá tốt trong hiệp một.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "việc man city kiểm soát bóng vượt trội và hệ thống lùi quanh vòng cấm của man utd chính là sự lựa chọn chiến thuật của erik ten hag. sau trận, chính hlv người hà lan khẳng định \"quỷ đỏ\" thực hiện đúng kế hoạch và đá tốt trong hiệp một.\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa text: viết thường, đưa text về utf-8\n",
    "\n",
    "\n",
    "import regex as re\n",
    "\n",
    "uniChars = \"àáảãạâầấẩẫậăằắẳẵặèéẻẽẹêềếểễệđìíỉĩịòóỏõọôồốổỗộơờớởỡợùúủũụưừứửữựỳýỷỹỵÀÁẢÃẠÂẦẤẨẪẬĂẰẮẲẴẶÈÉẺẼẸÊỀẾỂỄỆĐÌÍỈĨỊÒÓỎÕỌÔỒỐỔỖỘƠỜỚỞỠỢÙÚỦŨỤƯỪỨỬỮỰỲÝỶỸỴÂĂĐÔƠƯ\"\n",
    "unsignChars = \"aaaaaaaaaaaaaaaaaeeeeeeeeeeediiiiiooooooooooooooooouuuuuuuuuuuyyyyyAAAAAAAAAAAAAAAAAEEEEEEEEEEEDIIIOOOOOOOOOOOOOOOOOOOUUUUUUUUUUUYYYYYAADOOU\"\n",
    "\n",
    "\n",
    "def loaddicchar():\n",
    "    dic = {}\n",
    "    char1252 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        \"|\"\n",
    "    )\n",
    "    charutf8 = \"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\".split(\n",
    "        \"|\"\n",
    "    )\n",
    "    for i in range(len(char1252)):\n",
    "        dic[char1252[i]] = charutf8[i]\n",
    "    return dic\n",
    "\n",
    "\n",
    "dicchar = loaddicchar()\n",
    "\n",
    "\n",
    "def covert_unicode(txt):\n",
    "    return re.sub(\n",
    "        r\"à|á|ả|ã|ạ|ầ|ấ|ẩ|ẫ|ậ|ằ|ắ|ẳ|ẵ|ặ|è|é|ẻ|ẽ|ẹ|ề|ế|ể|ễ|ệ|ì|í|ỉ|ĩ|ị|ò|ó|ỏ|õ|ọ|ồ|ố|ổ|ỗ|ộ|ờ|ớ|ở|ỡ|ợ|ù|ú|ủ|ũ|ụ|ừ|ứ|ử|ữ|ự|ỳ|ý|ỷ|ỹ|ỵ|À|Á|Ả|Ã|Ạ|Ầ|Ấ|Ẩ|Ẫ|Ậ|Ằ|Ắ|Ẳ|Ẵ|Ặ|È|É|Ẻ|Ẽ|Ẹ|Ề|Ế|Ể|Ễ|Ệ|Ì|Í|Ỉ|Ĩ|Ị|Ò|Ó|Ỏ|Õ|Ọ|Ồ|Ố|Ổ|Ỗ|Ộ|Ờ|Ớ|Ở|Ỡ|Ợ|Ù|Ú|Ủ|Ũ|Ụ|Ừ|Ứ|Ử|Ữ|Ự|Ỳ|Ý|Ỷ|Ỹ|Ỵ\",\n",
    "        lambda x: dicchar[x.group()],\n",
    "        txt,\n",
    "    )\n",
    "\n",
    "\n",
    "text = (covert_unicode(text)).lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: underthesea in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (6.8.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (8.1.7)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (0.9.10)\n",
      "Requirement already satisfied: nltk in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (3.8.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (4.66.2)\n",
      "Requirement already satisfied: requests in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (2.31.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (1.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (1.4.1.post1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (6.0.1)\n",
      "Requirement already satisfied: underthesea-core==1.0.4 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from underthesea) (1.0.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.6)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk->underthesea) (2023.12.25)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->underthesea) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->underthesea) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->underthesea) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->underthesea) (2024.2.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in c:\\users\\lecy\\appdata\\roaming\\python\\python311\\site-packages (from scikit-learn->underthesea) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->underthesea) (1.12.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lecy\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn->underthesea) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "việc man city kiểm soát bóng vượt trội và hệ thống lùi quanh vòng cấm của man utd chính là sự lựa chọn chiến thuật của erik ten hag. sau trận, chính hlv người hà lan khẳng định \"quỷ đỏ\" thực hiện đúng kế hoạch và đá tốt trong hiệp một.\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hóa kiểu gõ dấu (tiếng Việt)\n",
    "\n",
    "from underthesea import text_normalize\n",
    "\n",
    "\n",
    "def fix_sentence(string):\n",
    "    return text_normalize(string)\n",
    "\n",
    "\n",
    "fix_sentence(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "việc man city kiểm soát bóng vượt trội và hệ thống lùi quanh vòng cấm của man utd chính là sự lựa chọn chiến thuật của erik ten hag. sau trận, chính hlv người hà lan khẳng định \"quỷ đỏ\" thực hiện đúng kế hoạch và đá tốt trong hiệp một.\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn hoá text: Loại Bỏ Ký Tự Rỗng và Dấu Cách Thừa\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_extra_whitespaces(input_string):\n",
    "    trimmed_string = input_string.strip()\n",
    "    no_extra_whitespaces_string = re.sub(r\"\\s+\", \" \", trimmed_string)\n",
    "    return no_extra_whitespaces_string\n",
    "\n",
    "\n",
    "text = remove_extra_whitespaces(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "việc man city kiểm soát bóng vượt trội và hệ thống lùi quanh vòng cấm của man utd chính là sự lựa chọn chiến thuật của erik ten hag.\n",
      "sau trận, chính hlv người hà lan khẳng định \"quỷ đỏ\" thực hiện đúng kế hoạch và đá tốt trong hiệp một.\n"
     ]
    }
   ],
   "source": [
    "# Tách văn bản thành các câu\n",
    "from underthesea import sent_tokenize\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "việc man city kiểm soát bóng vượt trội và hệ thống lùi quanh vòng cấm của man utd chính là sự lựa chọn chiến thuật của erik ten hag sau trận chính hlv người hà lan khẳng định quỷ đỏ thực hiện đúng kế hoạch và đá tốt trong hiệp một\n"
     ]
    }
   ],
   "source": [
    "# Loại bỏ dấu câu\n",
    "import re\n",
    "\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    text_without_punctuation = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text_without_punctuation\n",
    "\n",
    "\n",
    "text = remove_punctuation(text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['việc', 'man', 'city', 'kiểm soát', 'bóng', 'vượt trội', 'và', 'hệ thống', 'lùi', 'quanh', 'vòng', 'cấm', 'của', 'man utd', 'chính', 'là', 'sự', 'lựa chọn', 'chiến thuật', 'của', 'erik', 'ten', 'hag', 'sau', 'trận', 'chính', 'hlv', 'người', 'hà lan', 'khẳng định', 'quỷ', 'đỏ', 'thực hiện', 'đúng', 'kế hoạch', 'và', 'đá', 'tốt', 'trong', 'hiệp', 'một']\n"
     ]
    }
   ],
   "source": [
    "# Tách từ trong câu\n",
    "from underthesea import word_tokenize\n",
    "\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['việc', 'man', 'city', 'kiểm soát', 'bóng', 'vượt trội', 'và', 'hệ thống', 'lùi', 'quanh', 'vòng', 'cấm', 'của', 'man utd', 'chính', 'là', 'sự', 'lựa chọn', 'chiến thuật', 'của', 'erik', 'ten', 'hag', 'sau', 'trận', 'chính', 'hlv', 'người', 'hà lan', 'khẳng định', 'quỷ', 'đỏ', 'thực hiện', 'đúng', 'kế hoạch', 'và', 'đá', 'tốt', 'trong', 'hiệp', 'một']\n"
     ]
    }
   ],
   "source": [
    "#Loại bỏ từ hiếm tránh overfitting trong các tác vụ học máy\n",
    "from collections import Counter\n",
    "\n",
    "def remove_rare_words(words, threshold=5):\n",
    "    word_freq = Counter(words)\n",
    "    filtered_words = [word for word in words if word_freq[word] >= threshold]\n",
    "    \n",
    "    return filtered_words\n",
    "\n",
    "words = remove_rare_words(words, threshold=1)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['man', 'city', 'kiểm soát', 'bóng', 'vượt trội', 'hệ thống', 'lùi', 'quanh', 'vòng', 'cấm', 'man utd', 'lựa chọn', 'chiến thuật', 'erik', 'ten', 'hag', 'trận', 'hlv', 'hà lan', 'quỷ', 'đỏ', 'kế hoạch', 'đá', 'hiệp']\n"
     ]
    }
   ],
   "source": [
    "# Loại bỏ stopwords\n",
    "import pandas as pd\n",
    "\n",
    "df_stopwords = pd.read_csv(\"vietnamese-stopwords.txt\", header=None, names=[\"stopword\"])\n",
    "stopwords_set = set(df_stopwords[\"stopword\"])\n",
    "\n",
    "\n",
    "def remove_stopwords(text, stopwords):\n",
    "    filtered_words = [word for word in text if word not in stopwords]\n",
    "    return filtered_words\n",
    "\n",
    "\n",
    "words = remove_stopwords(words, stopwords_set)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ra file CSV dữ liệu đầu ra\n",
    "import pandas as pd\n",
    "\n",
    "dfs = pd.DataFrame(sentences, columns=[\"Sentence\"])\n",
    "dfw = pd.DataFrame(words, columns=[\"Word\"])\n",
    "\n",
    "dfs.to_csv(\"sentences_normalized.csv\", index=True, encoding=\"utf-8-sig\")\n",
    "dfw.to_csv(\"words_normalized.csv\", index=True, encoding=\"utf-8-sig\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
